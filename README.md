# 推荐系统

#### 📌【论文一】DIN论文需要掌握的知识

论文关键掌握：**摘要、架构、PReLU、Dice、Mini-Batch-aware-Regulazation**

- 【摘要】传统的CTR解决方式就是：使用基于深度学习的模型，将**大规模稀疏输入特征**映射为**低维向量**，然后以分组（我理解的分组就是稀疏、稠密这种）的方式**转换成定长向量**，最后**拼接**起来输入到`MLP`中，以学习特征之间的非线性关系。但是，无论候选广告是什么，用户特征都会被压缩成一个固定长度的表示向量。固定长度向量的使用将是一个瓶颈，模型难以从丰富的历史行为中有效捕捉用户的不同兴趣，于是提出`DIN`。另外，为了帮助训练近亿级别的参数量，提出`Mini-Batch-aware-Regulazation`和`data Adaptive activation function`

- 【模型架构】1️⃣`Activation Unit`: 用户历史行为`embedding1`和候选广告`embedding2`做外积，结果是一个向量；将`embedding1`，`embedding2`和输出结果三者拼接，送入全连接层，最后得到兴趣权重$w_j$（标量）。2️⃣用户行为序列中的每个行为都会产生一个权重，将产生的权重$w_j$和对应的行为$e_j$相乘，然后做`sum pooling`，这样我们就得到了基于兴趣的用户行为特征向量表示。最后我们将用户画像特征、基于兴趣的用户行为特征、候选广告、上下文特征**拼接**送入`MLP`中，`Softmax`得到结果。核心公式：


$$
\mathbf{v}_U(A) = f(\mathbf{v}_A, \mathbf{e}_1, \mathbf{e}_2, \ldots, \mathbf{e}_H)
= \sum_{j=1}^{H} a(\mathbf{e}_j, \mathbf{v}_A) \mathbf{e}_j
= \sum_{j=1}^{H} w_j \mathbf{e}_j
$$

- 【`PRelU`和`Dice`】1️⃣`PRelU`和`Dice`二者都有一个自适应的激活函数，也就是说都有一个**控制函数**；`PRelU`的控制函数比较简单，输入$x$大于0度时候函数值为1，$x$小于0的时候函数值为0；这也是它的缺点：分界点总是0，这是一个硬性分解【但是在实际训练中，每层输入$x$的分布是不同的，零可能不是最合适的分界点】2️⃣而`Dice`中的控制函数，是一个s型曲线，实现了软切换。工作机制：如果x比当前`mini-batch`的平均值大很多，说明该输入是高激活——p(x)趋向于1，函数趋近于f(x)=$x$；如果$x$比当前`mini-batch`的平均值小很多，说明该输入是低激活——p(x)趋向于0，函数趋近于f(x) = $α$*$x$
- 【`Mini-Batch-aware-Regulazation`】工业级广告推荐系统中，输入特征：稀疏+维度高（6亿维）；1️⃣**传统正则化(L1/L2)的挑战：** 在大规模稀疏输入的场景下，每个`mini-batch`仅激活少量参数（如几十个商品ID），大多数特征在一个`batch`中根本没出现，若强行对所有参数做L2计算，需要访问全部`Embedding`矩阵，计算开销太大。2️⃣`Mini-Batch-aware-Regulazation`：只对当前`mini-batch`中真正出现的特征对应的 `embedding`向量加正则，并做归一化处理。
- 论文地址: https://arxiv.org/pdf/1706.06978



#### 📌【论文二】SIM论文需要掌握的知识

论文关键掌握：**解决的问题、General Search Unit、Exact Search Unit**

- 【解决的问题】主要解决传统CTR模型在面对**超长用户行为序列时难以精确建模兴趣**的问题；用户历史行为序列很长就会导致：**计算量大；存储难；**1️⃣`MIMN(Memory Interaction Network)` 缺点是无法兴趣建模2️⃣`DIN`缺点是面对工业界中的用户长行为序列，**DIN 是对全量用户行为做一次 attention 计算**；计算量和存储需求是不可接受。
- 【General Search Unit】粗排；即使用简单、低成本的搜索策略，过滤掉用户无关行为。`Hard-Search`和`Soft-Search`的区别在于相关性分数的计算方式不同。1️⃣`Hard-Search`：是一种**无参数**的搜索方式；只需要判断候选商品是否和用户行为属于同一个`category`，相关行为的相关性分数就是1，不相关的相关性分数就是0；2️⃣`Soft-Search`：有参数；用户行为向量$b_i$被映射为one-hot Vector，然后embedding为低维向量$e_i$，相关性分数就是低维用户行为向量和候选商品向量做内积得到的。

![image-20250506124920977](D:\Documents\推荐系统\论文图片\Readme公式图片\image-20250506124920977.png)

- 【Exact Search Unit】精排；使用attention类的复杂模型（如DIN、DIEN）进行兴趣建模。输入是GSU的筛选结果（长度通常数百以内）
- 论文地址：https://arxiv.org/pdf/2006.05639



#### 📌【论文三】YouTuBe论文需要掌握的知识

论文关键掌握：**YouTube召回、YouTube排序、训练数据的选取和生成、Example age 是什么？**

**矩阵分解（Matrix Factorization）** 是传统协同过滤中的核心方法

为了避免视频向量过于稀疏，使用`fixed vocabulary`对视频编码嵌入为高维向量。

假设用户点了视频a，那视频a对应的label是1，其他的视频label都是0。假设总共有N个视频，那就是N个d维视频向量，用户向量是d维的，用户的d维和这N个视频向量算相似度得到N个得分，再算`softmax`得到用户对N个视频的预估分，去和label算loss，这个就是右边的训练阶段。这样就可以学出每个视频的向量，然后拿来建索引，预估的时候就是拿一个用户的向量去这个索引里找出最像的k个视频，这就是左边部分。

3.1中提到：没有使用点赞/点踩这种指标，而是将用户完整看完一个视频作为一个正样本；（因为点赞量过于稀疏，可能用户看了10个视频才点赞了一次）；②这是一个百万级别的多分类问题，作者也尝试了层次`Softmax`（Word2Vec论文中的方式，利用了霍夫曼树的思想）的方法，但是效果不好；作者采用的是负采样方式，sample出来的负样本要和正例一起`softmax`，而不是像word2vec那样做k次二分类。

3.4中提到：采用随机留出（random hold-out）会破坏用户观看视频时的时序特征；所以采用`RollBack`的预测策略。

`video vector` 是`softmax`的权重矩阵；而`user vector`是`RelU`最后一层的输出

对于`YoutubeDNN`，构造正负样本的时候要使用滑动窗口的方式去构造，其次， 是训练数据来源于用户的隐式数据， 且 **用户看完了的视频作为正样本** ， 注意这里是看完了， 有一定的时长限制， 而不是仅仅曝光点击，有可能有误点的。 而负样本，是从视频库里面随机选取，或者在曝光过的里面随机选取用户没看过的作为负样本。

**训练数据中对于每个用户选取相同的样本数， 保证用户在损失函数等权重** ， 因为这样可以减少高度活跃用户对于loss的影响。



#### 📌【论文四】POSO论文需要掌握的知识

- 论文地址：https://arxiv.org/pdf/2108.04690

#### 📌【论文五】DIEN

关键：**DIEN模型三层架构、损失函数、 GRU和Attention的结合方式**

--------------------------------------------------------------------------------【三层架构】----------------------------------------------------------------------------------------

（1）**行为序列层**。其主要作用是把原始的用户行为序列id转换为Embedding。

（2）**兴趣抽取层**。其主要作用是通过序列模型模拟用户兴趣迁移，抽取用户兴趣。

（3）**兴趣演化层**。其主要作用是通过在兴趣抽取层基础上加入注意力机制，模拟与目标广告相关的兴趣演化过程。兴趣演化层是DIEN最重要的模块，也是最主要的创新点。

--------------------------------------------------------------------------------【损失函数】----------------------------------------------------------------------------------------

①在通常的CTR任务中，由于是0/1二分类任务，我们常常使用交叉熵作为损失函数【比较的是预测概率$P(x)$和真实标签$y$】②为了增强隐藏状态的表达能力，我们引入了$L_{aux}$作为辅助损失：**辅助损失函数（Auxiliary Loss）** ；通过对比学习约束每一步的隐藏状态：
$$
L_{\text{aux}} = -\frac{1}{N} \sum_{i=1}^N \sum_t \left( 
\log \sigma(\mathbf{h}_t^i, \mathbf{e}_b^i[t+1]) + \log (1 - \sigma(\mathbf{h}_t^i, \hat{\mathbf{e}}_b^i[t+1])) 
\right)
$$
- **$\mathbf{h}_t^i$**：用户 $i$ 在时间步 $t$ 的隐藏状态  
- **$\mathbf{e}_b^i[t+1]$**：真实下一步行为（正样本）  
- **$\hat{\mathbf{e}}_b^i[t+1]$**：负采样行为（负样本）  
- **$\sigma(\cdot)$**：Sigmoid 内积相似度：$\sigma(\mathbf{a}, \mathbf{b}) = \frac{1}{1+\exp(-\mathbf{a}^\top \mathbf{b})}$

<mark style="background-color: pink;">分两步讲一下这个公式：</mark>

- **正样本部分**：最大化 $h_t$与正样本行为(真实下一步)的相似度【正样本来源：用真实的下一个行为 $b_{t+1}$作为正样本】。
- **负样本部分**：最小化 $h_t$与负样本行为的相似度。【负样本来源：从未点击的商品中采样负样本】
- 最后：使用 Sigmoid内积 *σ*(h_t，e_t) 衡量相似性，而非概率输出。

**实际应用**：通常联合训练$L$=$L_{target}$+α$L_{aux}$，超参数 *α* 用来平衡两者权重；其中$L_{target}$用来监督的是全局的 $y$。而$L_{aux}$的监督信号是序列中下一步的真实行为$\mathbf{e}_b^i[t+1]$（正样本）和随机采样的负行为$\hat{\mathbf{e}}_b^i[t+1]$

------------------------------------------------------------------【 GRU和Attention的结合方式】---------------------------------------------------------------------------

模型中使用的是`AUGRU`，对原始更新门乘上一个attention分数

为什么要结合❓：传统 GRU 仅能捕捉行为之间的依赖关系，但无法直接表示用户的“兴趣”。所以要做一个attention

论文地址：https://arxiv.org/pdf/1809.03672







#### 📌【召回评估指标】

【命中率】单个用户的前K个推荐中，只要一个命中目标商品，就算是一次命中。

【`Precision@K`】召回K个商品，用户真正喜欢的商品数量所占的比例

【召回率】用户真正喜欢的商品中，有多少被推荐在前K个中

【AP】用来评估单个用户的召回效果；和被推荐商品的排名有关

【MAP】用来评估多个用户（整个推荐系统）的召回效果；所有用户的AP相加之后求平均。它衡量推荐系统在整个测试集上的表现。

#### 📌【排序评估指标】

【DCG】也是针对**单个用户**或**单个查询**的指标。DCG综合考虑了物品能带来的收益和其所在位置的折扣效应。特别关注<span style = "color:blue">**推荐顺序**的合理性。</span>

- 物品的收益用**相关性得分**（通常是点击率、评分、点赞等）表示。**rel值越大**，表示用户对该物品的偏好越高。

$$
DCG@K = \sum_{i=1}^{K} \frac{rel_i}{\log_2(i+1)}
$$

其中：

- **K**：推荐列表的长度。  
- **rel_i**：第 \(i\) 个推荐物品的相关性得分（收益）。  
- $log_2(i+1)$：折扣因子，表示排名靠后的物品对收益的贡献降低。  

【NDCG】：对DCG归一化

【AUC】、【GAUC】：在排序、召回的过程中都会用到；AUC衡量的是模型将正样本排序在负样本之前的能力，很适合推荐系统中样本分布不平衡的这种情况。提到AUC就不得不想到ROC曲线，曲线的横坐标是假阳率，纵坐标是真阳率，也就是召回率。AUC和阈值无关，能衡量不同阈值下，模型的分类能力。但是：**AUC不能反映排序位置这个信息。**



#### 📌LSTM和GRU

t时刻候选隐状态和更新门相乘之后，才得到t时刻隐状态；t时刻候选隐状态是重置门和t-1时刻隐状态相乘的结果；所以：

- 重置门重置的是上一时刻的**隐状态**（如果上一时刻的隐状态在这一时刻不重要了，那么重置门可以减少以往状态的影响）
- 更新门更新的是t时刻**候选隐状态**

$$
h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t
$$

从公式可以看出：

- $t$时刻隐状态的更新依赖于：**t-1时刻隐状态**和**t时刻的候选隐状态**；

- 【为什么缓解梯度消失？】当 $Z_t$很小 → $h_t \approx h_{t-1}$，模型就倾向保留上一时刻的信息。 此时，来自$X_t$的信息基本上被忽略。这样使得梯度在时间上传递时不会快速衰减（即不会变成0）

总结：这个结构使得网络<mark style="background-color: pink;">可以“跳过”一些无关时刻</mark>，避免梯度累积导致消失。









